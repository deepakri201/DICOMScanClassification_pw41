{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakri201/DICOMScanClassification_pw41/blob/main/DICOMScanClassification_user_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU-3NXF5A4RX"
      },
      "source": [
        "**DICOM Scan Classification**\n",
        "\n",
        "Project Week 41\n",
        "\n",
        "https://projectweek.na-mic.org/PW41_2024_MIT/Projects/AutomaticClassificationOfMrScanSequenceType/\n",
        "\n",
        "---\n",
        "\n",
        "This notebook allows the user to run inference using pre-trained models for DICOM scan classification for prostate MR images. The models were developed for MIDL 2024, see more details in the arxiv submission here: https://arxiv.org/abs/2404.10892. See the original github repository for MIDL 2024 here: https://github.com/deepakri201/DICOMScanClassification.\n",
        "\n",
        "---\n",
        "\n",
        "Deepa Krishnaswamy\n",
        "\n",
        "Brigham and Women's Hospital\n",
        "\n",
        "June 2024\n",
        "\n",
        "---\n",
        "\n",
        "Notes:\n",
        "- All of the models were trained/validated using QIN-Prostate-Repeatability and ProstateX. Therefore, the following patients should NOT be used for inference:\n",
        "   - QIN-Prostate-Repeatability - PCAMPMRI-00001 to PCAMPMRI-00012\n",
        "   - ProstateX - ProstateX-0000 to ProstateX-0275\n",
        "\n",
        "Notes to do:\n",
        "- Downloads the trained model from github release attachments -\n",
        "- User gives an SOPInstanceUID to a specific prostate slice, download using idc-index -\n",
        "- Obtain most of the metadata automatically except for is_4D, user must set?\n",
        "- Then the notebook preprocesses the data -\n",
        "- Run inference and gives classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9fw-iudCZg9"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User modify this if using in colab\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  SeriesInstanceUID = \"1.3.6.1.4.1.14519.5.2.1.195215726513917488743459416430092664258\""
      ],
      "metadata": {
        "id": "G6bdhho9WxDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "Sv6Z2Nrq7DN1"
      },
      "outputs": [],
      "source": [
        "SeriesInstanceUID=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4xm6o7NN2bir"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install SimpleITK\n",
        "    !pip install pydicom\n",
        "    !pip install --upgrade idc-index\n",
        "    !pip install nibabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JUcW9oiv2quu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a281387a-63a5-48bf-d1bc-05c05072976e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-25 16:01:14--  https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20240202/dcm2niix_lnx.zip [following]\n",
            "--2024-06-25 16:01:14--  https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20240202/dcm2niix_lnx.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/25434012/d2b10421-c465-4a96-809c-aa2068482148?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240625T160114Z&X-Amz-Expires=300&X-Amz-Signature=858e03b2fb6b6ba5219bbcade363656a4448dc340800c87ceec3a0ace2f467e4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25434012&response-content-disposition=attachment%3B%20filename%3Ddcm2niix_lnx.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-06-25 16:01:14--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/25434012/d2b10421-c465-4a96-809c-aa2068482148?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240625T160114Z&X-Amz-Expires=300&X-Amz-Signature=858e03b2fb6b6ba5219bbcade363656a4448dc340800c87ceec3a0ace2f467e4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25434012&response-content-disposition=attachment%3B%20filename%3Ddcm2niix_lnx.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 888918 (868K) [application/octet-stream]\n",
            "Saving to: ‘dcm2niix_lnx.zip’\n",
            "\n",
            "dcm2niix_lnx.zip    100%[===================>] 868.08K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-06-25 16:01:14 (14.9 MB/s) - ‘dcm2niix_lnx.zip’ saved [888918/888918]\n",
            "\n",
            "Archive:  dcm2niix_lnx.zip\n",
            "  inflating: dcm2niix                \n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget \"https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip\" \\\n",
        "    && unzip \"dcm2niix_lnx.zip\" \\\n",
        "    && rm \"dcm2niix_lnx.zip\" \\\n",
        "    && mv dcm2niix /usr/local/bin/dcm2niix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SYu2FvZK2_QF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget -O scaling_factors.csv https://github.com/deepakri201/DICOMScanClassification/releases/download/v1.0.0/scaling_factors.csv\n",
        "    !wget -O metadata_only_model.zip  https://github.com/deepakri201/DICOMScanClassification/releases/download/v1.0.0/metadata_only_model.zip\n",
        "    !wget -O images_only_model.zip https://github.com/deepakri201/DICOMScanClassification/releases/download/v1.0.0/images_only_model.zip\n",
        "    !wget -O images_and_metadata_model.zip https://github.com/deepakri201/DICOMScanClassification/releases/download/v1.0.0/images_and_metadata_model.zip\n",
        "    !unzip \"metadata_only_model.zip\" -d \"metadata_only_model/\"\n",
        "    !unzip \"images_only_model.zip\" -d \"images_only_model/\"\n",
        "    !unzip \"images_and_metadata_model.zip\" -d \"images_and_metadata_model/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n7UhAQn-BXWe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5GW9-sX93xt5"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bTre_FIjw2fu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7uwZqCvMw6GW"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# random.seed(0)\n",
        "#tf.random.set_seed(0)\n",
        "# np.random.seed(0)\n",
        "#os.environ['PYTHONHASHSEED']=str(0)\n",
        "\n",
        "# Set the seed using keras.utils.set_random_seed. This will set:\n",
        "# 1) `numpy` seed\n",
        "# 2) backend random seed\n",
        "# 3) `python` random seed\n",
        "keras.utils.set_random_seed(0)\n",
        "\n",
        "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
        "# but it will affect the overall performance, so be mindful of that.\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "21xYZm_2IIT2"
      },
      "outputs": [],
      "source": [
        "from idc_index import index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aNx_EJ6hLPyS"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_qKJqC2OW-18"
      },
      "outputs": [],
      "source": [
        "# Do we need to unzip the folds? Or just rename as .keras files instead of .zip files??\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL09qlT6IKXA"
      },
      "source": [
        "# Choose series to classify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWCw7FDmJubq"
      },
      "source": [
        "Ideally, we would only download the single SOPInstanceUID we want to classify instead of entire series. We do this for a few reasons:\n",
        "- First, since it's harder for the user to choose the precise mid-slice slice, we instead download the entire series, convert to nifti, and choose the mid slice for them. We could also read the dicom files using pydicom, order by the image position patient, and then choose the middle slice.\n",
        "- Secondly, idc-index currently does not support the download of a single SOPInstanceUID.\n",
        "\n",
        "Downloading the entire series is further complicated by DWI, where we may have multiple 3D volumes in a series. We rely on dcm2niix to convert these multiple volumes, and for now, pick the mid slice from the first one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_tIky3fZOo_",
        "outputId": "4bb5f2b5-470c-4916-db07-7cf557a1d1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|██████████| 950k/950k [00:01<00:00, 941kB/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "client = index.IDCClient()\n",
        "\n",
        "# Download files\n",
        "download_path = \"raw\"\n",
        "if not os.path.isdir(download_path):\n",
        "  os.mkdir(download_path)\n",
        "# if directory exists, remove files from it,\n",
        "else:\n",
        "  shutil.rmtree(download_path)\n",
        "\n",
        "# Download using s5cmd\n",
        "client.download_dicom_series(SeriesInstanceUID, download_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.isdir(\"nii\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATJ9GjkTUYUE",
        "outputId": "709bc8d3-d28d-49c0-a255-9a6d38bf4d81"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Yvv5CMZOo_",
        "outputId": "788ec18c-bbb9-4179-f52d-c0cc5d35d796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o nii  raw \n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Convert to nifti\n",
        "nifti_directory = \"nii\"\n",
        "if not os.path.isdir(nifti_directory):\n",
        "  os.mkdir(nifti_directory)\n",
        "else:\n",
        "  shutil.rmtree(nifti_directory)\n",
        "\n",
        "cmd = 'dcm2niix -z y -m y -o %s  %s ' % (nifti_directory, download_path)\n",
        "print(cmd)\n",
        "ret = os.system(cmd)\n",
        "print(ret)\n",
        "\n",
        "# Rename file\n",
        "nii_file_orig = [os.path.join(nifti_directory,f) for f in os.listdir(nifti_directory) if f.endswith('.nii.gz')][0]\n",
        "nii_file = \"mri_image.nii.gz\"\n",
        "os.rename(nii_file_orig, nii_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF-vegb-Jsfq"
      },
      "outputs": [],
      "source": [
        "# Then extract the middle slice\n",
        "# In the case of DWI, take the middle slice from the first volume\n",
        "\n",
        "nii = nib.load(nii_file)\n",
        "imgs = nii.get_fdata()\n",
        "num_slices = imgs.shape[2]\n",
        "print(\"num_slices: \" + str(num_slices))\n",
        "\n",
        "mid_slice_index = np.floor(num_slices/2).astype(np.int16)\n",
        "print('mid_slice_index: ' + str(mid_slice_index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4NforHFNHAG"
      },
      "outputs": [],
      "source": [
        "# Get the middle slice and dispay\n",
        "\n",
        "mid_slice = imgs[:,:,mid_slice_index]\n",
        "print('mid_slice shape: ' + str(mid_slice.shape))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.rot90(mid_slice), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# matplotlib will flip it - but our image is actually the right orientation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tOPEqFFC47P"
      },
      "source": [
        "# Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s48wZj2Kve5"
      },
      "source": [
        "Here we resize the iamge data to 64x64, and rescale between 0 and 1. We also extract the metadata needed from the DICOM files. We can use any of the DICOM files to get the metadata, for now. We use pydicom for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUYUZ8BFK3zq"
      },
      "outputs": [],
      "source": [
        "# First resize image to 64x64 as this is what our pre-trained models take as input\n",
        "\n",
        "resample_size = [64,64]\n",
        "\n",
        "image = mid_slice.astype(np.float32)\n",
        "original_spacing = nii.header['pixdim'][1:3]\n",
        "\n",
        "# resample\n",
        "image_sitk = sitk.GetImageFromArray(image, sitk.sitkFloat32)\n",
        "image_sitk.SetSpacing(np.array(original_spacing, dtype='float32').tolist())\n",
        "image_sitk.SetOrigin((0,0))\n",
        "original_size = image_sitk.GetSize()\n",
        "# print('original_size: ' + str(original_size))\n",
        "\n",
        "if len(original_size) == 2:\n",
        "  original_size = original_size + (1, )\n",
        "\n",
        "new_spacing = [original_size[0]*original_spacing[0]/resample_size[0],\n",
        "              original_size[1]*original_spacing[1]/resample_size[1]]\n",
        "\n",
        "# image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)\n",
        "\n",
        "ResampleFilter = sitk.ResampleImageFilter()\n",
        "ResampleFilter.SetInterpolator(sitk.sitkBSpline)\n",
        "ResampleFilter.SetOutputSpacing(new_spacing)\n",
        "ResampleFilter.SetSize(resample_size)\n",
        "ResampleFilter.SetOutputDirection(image_sitk.GetDirection())\n",
        "ResampleFilter.SetOutputOrigin(image_sitk.GetOrigin())\n",
        "ResampleFilter.SetOutputPixelType(image_sitk.GetPixelID())\n",
        "# print(image_sitk.GetPixelIDTypeAsString())\n",
        "ResampleFilter.SetTransform(sitk.Transform())\n",
        "image_resampled_sitk = ResampleFilter.Execute(image_sitk)\n",
        "\n",
        "# rescale image\n",
        "image_resampled_rescaled_sitk = sitk.RescaleIntensity(image_resampled_sitk, 0, 1)\n",
        "image_resampled_rescaled = sitk.GetArrayFromImage(image_resampled_rescaled_sitk)\n",
        "# print('image_resampled_rescaled: ' + str(image_resampled_rescaled.shape))\n",
        "\n",
        "image_preprocessed = np.copy(image_resampled_rescaled)\n",
        "print('image_preprocessed shape: ' + str(image_preprocessed.shape) + ', min: ' + str(np.min(image_preprocessed)) + ', max: ' + str(np.max(image_preprocessed)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgrPywCRPyBB"
      },
      "outputs": [],
      "source": [
        "# Extract the metadata needed from the DICOM files using pydicom\n",
        "\n",
        "# Read DICOM file\n",
        "dicom_files = glob.glob(os.path.join(download_path, '**/**/**/**/*.dcm'), recursive=True)\n",
        "print('num dicom_files: ' + str(len(dicom_files)))\n",
        "dicom_filename = dicom_files[0]\n",
        "print('dicom_filename: ' + str(dicom_filename))\n",
        "dataset = pydicom.dcmread(dicom_filename)\n",
        "\n",
        "# Get DICOM metadata\n",
        "RepetitionTime = dataset.RepetitionTime\n",
        "EchoTime = dataset.EchoTime\n",
        "FlipAngle = dataset.FlipAngle\n",
        "if \"ContrastBolusAgent\" in dataset:\n",
        "  ContrastBolusAgent = dataset.ContrastBolusAgent\n",
        "  if (ContrastBolusAgent is None):\n",
        "    has_contrast = False\n",
        "  else:\n",
        "    has_contrast = True\n",
        "else:\n",
        "  has_contrast = False\n",
        "ScanningSequence = dataset.ScanningSequence\n",
        "\n",
        "print('RepetitionTime: ' + str(RepetitionTime))\n",
        "print('EchoTime: ' + str(EchoTime))\n",
        "print('FlipAngle: ' + str(FlipAngle))\n",
        "print('has_contrast: ' + str(has_contrast))\n",
        "print('ScanningSequence: ' + str(ScanningSequence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovb_nnFNbGif"
      },
      "outputs": [],
      "source": [
        "# Get if is_4D or not - using the DICOM ImagePositionPatient field\n",
        "\n",
        "dicom_files = glob.glob(os.path.join(download_path, '**/**/**/**/*.dcm'), recursive=True)\n",
        "dicom_files = list(set(list(dicom_files)))\n",
        "num_dicom_files = len(dicom_files)\n",
        "print('num dicom_files: ' + str(num_dicom_files))\n",
        "\n",
        "is_4D = False\n",
        "\n",
        "# read all the DICOM files\n",
        "num_files = len(dicom_files)\n",
        "IPP = []\n",
        "for n in range(0,num_files):\n",
        "  ds = pydicom.read_file(dicom_files[n])\n",
        "  IPP.append(ds.ImagePositionPatient)\n",
        "\n",
        "# get the unique number of ImagePositionPatient values\n",
        "unique_IPP = [f[2] for f in IPP]\n",
        "num_unique_IPP = len(unique_IPP)\n",
        "print('num_unique_IPP: ' + str(num_unique_IPP))\n",
        "\n",
        "# assign is_4D=True or False\n",
        "# We would have more dicom files than unique IPP if DWI for instance\n",
        "if (num_dicom_files / num_unique_IPP) > 1:\n",
        "  is_4D = True\n",
        "else:\n",
        "  is_4D = False\n",
        "\n",
        "print('is_4D: ' + str(is_4D))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW-2KdRkS3Fi"
      },
      "outputs": [],
      "source": [
        "# Preprocess the metadata ScanningSequence to has_scanningSequence_GR, has_scanningSequence_SE, has_scanningSequence_EP\n",
        "\n",
        "if 'SE' in ScanningSequence:\n",
        "  has_scanningSequence_SE = True\n",
        "else:\n",
        "  has_scanningSequence_SE = False\n",
        "\n",
        "if 'EP' in ScanningSequence:\n",
        "  has_scanningSequence_EP = True\n",
        "else:\n",
        "  has_scanningSequence_EP = False\n",
        "\n",
        "if 'GR' in ScanningSequence:\n",
        "  has_scanningSequence_GR = True\n",
        "else:\n",
        "  has_scanningSequence_GR = False\n",
        "\n",
        "print('has_scanningSequence_SE: ' + str(has_scanningSequence_SE))\n",
        "print('has_scanningSequence_EP: ' + str(has_scanningSequence_EP))\n",
        "print('has_scanningSequence_GR: ' + str(has_scanningSequence_GR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsPeSd7XYkVC"
      },
      "outputs": [],
      "source": [
        "# Preprocess the numeric metadata (RepetitionTime, EchoTime, FlipAngle) by applying the scaling factors from the training data\n",
        "\n",
        "scaling_factors_df = pd.read_csv('scaling_factors.csv')\n",
        "\n",
        "RepetitionTime_scaled = (RepetitionTime - scaling_factors_df['RepetitionTime_min'].values[0]) / (scaling_factors_df['RepetitionTime_max'].values[0] - scaling_factors_df['RepetitionTime_min'].values[0])\n",
        "EchoTime_scaled = (EchoTime - scaling_factors_df['EchoTime_min'].values[0]) / (scaling_factors_df['EchoTime_max'].values[0] - scaling_factors_df['EchoTime_min'].values[0])\n",
        "FlipAngle_scaled = (FlipAngle - scaling_factors_df['FlipAngle_min'].values[0]) / (scaling_factors_df['FlipAngle_max'].values[0] - scaling_factors_df['FlipAngle_min'].values[0])\n",
        "\n",
        "print('RepetitionTime_scaled: ' + str(RepetitionTime_scaled))\n",
        "print('EchoTime_scaled: ' + str(EchoTime_scaled))\n",
        "print('FlipAngle_scaled: ' + str(FlipAngle_scaled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiWUfmTWYVnu"
      },
      "outputs": [],
      "source": [
        "# Put together the metadata in the same order as the training/validation data\n",
        "\n",
        "# 'RepetitionTime', 'EchoTime', 'FlipAngle', 'has_contrast',\n",
        "# 'has_scanningSequence_SE', 'has_scanningSequence_EP',\n",
        "# 'has_scanningSequence_GR', 'is_4D'\n",
        "\n",
        "# One metadata for the RF model\n",
        "metadata_for_rf_model = np.asarray([RepetitionTime, EchoTime, FlipAngle,\n",
        "                                    has_contrast,\n",
        "                                    has_scanningSequence_SE, has_scanningSequence_EP, has_scanningSequence_GR,\n",
        "                                    is_4D])\n",
        "print('metadata_for_rf_model: ' + str(metadata_for_rf_model))\n",
        "\n",
        "# One metadata for the images+metadata model\n",
        "metadata_for_cnn_model = np.asarray([RepetitionTime_scaled, EchoTime_scaled, FlipAngle_scaled,\n",
        "                                     has_contrast,\n",
        "                                     has_scanningSequence_SE, has_scanningSequence_EP, has_scanningSequence_GR,\n",
        "                                     is_4D])\n",
        "print('metadata_for_cnn_model: ' + str(metadata_for_cnn_model))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovdZrQjxYhe"
      },
      "source": [
        "# Set up the ground truth values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X6nb_6ExaFr"
      },
      "outputs": [],
      "source": [
        "gt_keep =  ['T2_weighted_axial', 'DWI', 'ADC', 'DCE']\n",
        "gt_keep_values = np.arange(0,len(gt_keep),1)\n",
        "\n",
        "# create dictionary of these\n",
        "gt_dict = {gt_keep[i]: gt_keep_values[i] for i in range(len(gt_keep))}\n",
        "print('gt_dict: ' + str(gt_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLbj2QKUK4N8"
      },
      "source": [
        "# Perform inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LtHL8iRK6EL"
      },
      "outputs": [],
      "source": [
        "# Metadata only model - random forest classification\n",
        "\n",
        "metadata_only_model_filename = 'metadata_only_model/metadata_only_model/metadata_only_model.pkl'\n",
        "print('metadata_only_model_filename: ' + str(metadata_only_model_filename))\n",
        "\n",
        "with open(metadata_only_model_filename, 'rb') as f:\n",
        "    clf = pickle.load(f)\n",
        "\n",
        "# Perform inference\n",
        "\n",
        "metadata_for_rf_model = np.asarray(metadata_for_rf_model).reshape(-1,1)\n",
        "metadata_for_rf_model = np.transpose(metadata_for_rf_model)\n",
        "print(metadata_for_rf_model.shape)\n",
        "\n",
        "pred = clf.predict(metadata_for_rf_model)[0]\n",
        "pred_class = list(gt_dict.keys())[list(gt_dict.values()).index(pred)]\n",
        "\n",
        "print('pred value: ' + str(pred))\n",
        "print('pred class: ' + str(pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6iYUoXowDTL"
      },
      "outputs": [],
      "source": [
        "# Images only model - CNN classification\n",
        "\n",
        "images_only_model_filename_0_zip = 'images_only_model/images_only_model/images_only_model_fold0.zip'\n",
        "images_only_model_filename_1_zip = 'images_only_model/images_only_model/images_only_model_fold1.zip'\n",
        "images_only_model_filename_2_zip = 'images_only_model/images_only_model/images_only_model_fold2.zip'\n",
        "images_only_model_filename_3_zip = 'images_only_model/images_only_model/images_only_model_fold3.zip'\n",
        "\n",
        "images_only_model_filename_0_keras = 'images_only_model/images_only_model/images_only_model_fold0.keras'\n",
        "images_only_model_filename_1_keras = 'images_only_model/images_only_model/images_only_model_fold1.keras'\n",
        "images_only_model_filename_2_keras = 'images_only_model/images_only_model/images_only_model_fold2.keras'\n",
        "images_only_model_filename_3_keras = 'images_only_model/images_only_model/images_only_model_fold3.keras'\n",
        "\n",
        "!cp $images_only_model_filename_0_zip $images_only_model_filename_0_keras\n",
        "!cp $images_only_model_filename_1_zip $images_only_model_filename_1_keras\n",
        "!cp $images_only_model_filename_2_zip $images_only_model_filename_2_keras\n",
        "!cp $images_only_model_filename_3_zip $images_only_model_filename_3_keras\n",
        "\n",
        "loaded_model_0 = keras.models.load_model(images_only_model_filename_0_keras)\n",
        "loaded_model_1 = keras.models.load_model(images_only_model_filename_1_keras)\n",
        "loaded_model_2 = keras.models.load_model(images_only_model_filename_2_keras)\n",
        "loaded_model_3 = keras.models.load_model(images_only_model_filename_3_keras)\n",
        "\n",
        "print('image_preprocessed: ' + str(image_preprocessed.shape))\n",
        "image_preprocessed_input = np.copy(image_preprocessed)\n",
        "image_preprocessed_input = np.expand_dims(image_preprocessed_input,2)\n",
        "image_preprocessed_input = np.moveaxis(image_preprocessed_input, 2, 0)\n",
        "image_preprocessed_input = np.expand_dims(image_preprocessed_input,3)\n",
        "\n",
        "# predict for each fold\n",
        "model_list = [loaded_model_0, loaded_model_1, loaded_model_2, loaded_model_3]\n",
        "for n in range(0,len(model_list)):\n",
        "  loaded_model = model_list[n]\n",
        "  predictions = loaded_model.predict(image_preprocessed_input)\n",
        "  scores = [tf.nn.softmax(f) for f in predictions]\n",
        "  pred = [np.argmax(f) for f in scores]\n",
        "  pred_class = list(gt_dict.keys())[list(gt_dict.values()).index(pred)]\n",
        "  print('predictions for model fold: ' + ' pred value: ' + str(pred) + ' pred class: ' + str(pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkfoE-9rynF_"
      },
      "outputs": [],
      "source": [
        "# Images and metadata model - CNN classification\n",
        "\n",
        "images_and_metadata_model_filename_0_zip = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold0.zip'\n",
        "images_and_metadata_model_filename_1_zip = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold1.zip'\n",
        "images_and_metadata_model_filename_2_zip = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold2.zip'\n",
        "images_and_metadata_model_filename_3_zip = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold3.zip'\n",
        "\n",
        "images_and_metadata_model_filename_0_keras = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold0.keras'\n",
        "images_and_metadata_model_filename_1_keras = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold1.keras'\n",
        "images_and_metadata_model_filename_2_keras = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold2.keras'\n",
        "images_and_metadata_model_filename_3_keras = 'images_and_metadata_model/images_and_metadata_model/images_and_metadata_model_fold3.keras'\n",
        "\n",
        "!cp $images_and_metadata_model_filename_0_zip $images_and_metadata_model_filename_0_keras\n",
        "!cp $images_and_metadata_model_filename_1_zip $images_and_metadata_model_filename_1_keras\n",
        "!cp $images_and_metadata_model_filename_2_zip $images_and_metadata_model_filename_2_keras\n",
        "!cp $images_and_metadata_model_filename_3_zip $images_and_metadata_model_filename_3_keras\n",
        "\n",
        "loaded_model_0 = keras.models.load_model(images_and_metadata_model_filename_0_keras)\n",
        "loaded_model_1 = keras.models.load_model(images_and_metadata_model_filename_1_keras)\n",
        "loaded_model_2 = keras.models.load_model(images_and_metadata_model_filename_2_keras)\n",
        "loaded_model_3 = keras.models.load_model(images_and_metadata_model_filename_3_keras)\n",
        "\n",
        "print('image_preprocessed: ' + str(image_preprocessed.shape))\n",
        "image_preprocessed_input = np.copy(image_preprocessed)\n",
        "image_preprocessed_input = np.expand_dims(image_preprocessed_input,2)\n",
        "image_preprocessed_input = np.moveaxis(image_preprocessed_input, 2, 0)\n",
        "image_preprocessed_input = np.expand_dims(image_preprocessed_input,3)\n",
        "\n",
        "print(\"metadata_for_cnn_model: \" + str(metadata_for_cnn_model.shape))\n",
        "metadata_for_cnn_model = np.asarray(metadata_for_cnn_model).reshape(-1,1)\n",
        "metadata_for_cnn_model = np.transpose(metadata_for_cnn_model)\n",
        "metadata_for_cnn_model_input = np.expand_dims(metadata_for_cnn_model,2)\n",
        "print(\"metadata_for_cnn_model_input: \" + str(metadata_for_cnn_model_input.shape))\n",
        "\n",
        "# predict for each fold\n",
        "model_list = [loaded_model_0, loaded_model_1, loaded_model_2, loaded_model_3]\n",
        "for n in range(0,len(model_list)):\n",
        "  loaded_model = model_list[n]\n",
        "  predictions = loaded_model.predict([image_preprocessed_input, metadata_for_cnn_model_input])\n",
        "  scores = [tf.nn.softmax(f) for f in predictions]\n",
        "  pred = [np.argmax(f) for f in scores]\n",
        "  pred_class = list(gt_dict.keys())[list(gt_dict.values()).index(pred)]\n",
        "  print('predictions for model fold: ' + ' pred value: ' + str(pred) + ' pred class: ' + str(pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgQOsxCbXD2d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}