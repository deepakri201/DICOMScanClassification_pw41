{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "C4MiwWuk9z8y",
        "KX9UyCpY-AcN",
        "98eqUbfu-DGn",
        "HxOd_I0r-P3m"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNqnNd0BedpTlzbiGl15jhX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakri201/DICOMScanClassification_pw41/blob/main/MRSegmentator_on_IDC_data_installing_python3_11_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MRSegmentator on IDC data\n",
        "\n",
        "https://github.com/hhaentze/MRSegmentator\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Deepa Krishnaswamy\n",
        "\n",
        "Brigham and Women's Hospital\n",
        "\n",
        "June 2024\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Notes:\n",
        "- update colab version to 3.11: https://www.geeksforgeeks.org/how-to-update-google-colabs-python-version/\n",
        "- updating pip: https://askubuntu.com/questions/1025189/pip-is-not-working-importerror-no-module-named-pip-internal"
      ],
      "metadata": {
        "id": "YBeYVv1p49mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "BRy61HmKASAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "n7UhAQn-BXWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check current python environment\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEeo8P8qV0JX",
        "outputId": "8a442b75-b04f-4084-eb0e-5dc1da26d669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository ppa:deadsnakes/ppa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naRIqwtaIv6A",
        "outputId": "a26ac018-68ab-4018-e5c2-b1bcbbb8a5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository: 'deb https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 20.04 (focal) Python3.5 - Python3.7, Python3.9 - Python3.13\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11 - Python3.13\n",
            "- Ubuntu 24.04 (noble) Python3.7 - Python3.11, Python3.13\n",
            "- Note: Python2.7 (focal, jammy), Python 3.8 (focal), Python 3.10 (jammy), Python3.12 (noble) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for focal, older python versions require libssl<1.1 so they are not currently built\n",
            "- Note: for jammy and noble, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            "More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Press [ENTER] to continue or Ctrl-c to cancel.Aborted.\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK4_pHWcATwz",
        "outputId": "924d3b68-db0e-44b8-ec7e-0035257fb03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [1 InRelease 3,626\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to ppa\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,393 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,189 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,556 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 7,330 kB in 1s (5,452 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiXpAfAVIy-5",
        "outputId": "94dbdf3c-392f-4aa1-fa9c-143156d0e6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.11-minimal libpython3.11-stdlib mailcap mime-support\n",
            "  python3.11-minimal\n",
            "Suggested packages:\n",
            "  python3.11-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.11-minimal libpython3.11-stdlib mailcap mime-support python3.11\n",
            "  python3.11-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 5,832 kB of archives.\n",
            "After this operation, 21.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-minimal amd64 3.11.9-1+jammy1 [884 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-minimal amd64 3.11.9-1+jammy1 [2,355 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-stdlib amd64 3.11.9-1+jammy1 [1,925 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11 amd64 3.11.9-1+jammy1 [640 kB]\n",
            "Fetched 5,832 kB in 11s (546 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.11-minimal:amd64.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.11-minimal_3.11.9-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11-minimal:amd64 (3.11.9-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11-minimal.\n",
            "Preparing to unpack .../1-python3.11-minimal_3.11.9-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11-minimal (3.11.9-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.11-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.11-stdlib_3.11.9-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11-stdlib:amd64 (3.11.9-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11.\n",
            "Preparing to unpack .../5-python3.11_3.11.9-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11 (3.11.9-1+jammy1) ...\n",
            "Setting up libpython3.11-minimal:amd64 (3.11.9-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up python3.11-minimal (3.11.9-1+jammy1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.11-stdlib:amd64 (3.11.9-1+jammy1) ...\n",
            "Setting up python3.11 (3.11.9-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo7fulLtAUel",
        "outputId": "452cfa0f-1878-4d0a-a7d5-f354f8711d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.11 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --config python3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltr843aTAWU7",
        "outputId": "3458f67f-aa00-41fb-a57f-3b17d8270ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.11\n",
            "Nothing to configure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e_XM3uAAcFN",
        "outputId": "0f2920e2-c29e-4bb2-c99e-8c18502e5fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.11-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3.11 get-pip.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajKKlAT7Ac1t",
        "outputId": "e2255a64-57aa-4c2d-ec96-b66914c42c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.11-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "--2024-06-25 17:38:56--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2276232 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.17M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-06-25 17:38:56 (45.1 MB/s) - ‘get-pip.py’ saved [2276232/2276232]\n",
            "\n",
            "Collecting pip\n",
            "  Using cached pip-24.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-70.1.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Using cached pip-24.1-py3-none-any.whl (1.8 MB)\n",
            "Downloading setuptools-70.1.1-py3-none-any.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.3/883.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.1 setuptools-70.1.1 wheel-0.43.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3.11 -m pip install [package_name]\n"
      ],
      "metadata": {
        "id": "djm3d1AwAfPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip\n",
        "!unzip dcm2niix_lnx.zip\n",
        "!cp /content/dcm2niix /usr/local/bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e075c353-cb93-424b-c74f-77e6e99e88e6",
        "id": "XqigTMwrBBLA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-25 17:39:01--  https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20240202/dcm2niix_lnx.zip [following]\n",
            "--2024-06-25 17:39:01--  https://github.com/rordenlab/dcm2niix/releases/download/v1.0.20240202/dcm2niix_lnx.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/25434012/d2b10421-c465-4a96-809c-aa2068482148?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240625T173901Z&X-Amz-Expires=300&X-Amz-Signature=e5d1d9867435eff499ee32bc2bdc74fd0cf83b2b0342407dc320e7dfc0b19a4e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25434012&response-content-disposition=attachment%3B%20filename%3Ddcm2niix_lnx.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-06-25 17:39:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/25434012/d2b10421-c465-4a96-809c-aa2068482148?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240625T173901Z&X-Amz-Expires=300&X-Amz-Signature=e5d1d9867435eff499ee32bc2bdc74fd0cf83b2b0342407dc320e7dfc0b19a4e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=25434012&response-content-disposition=attachment%3B%20filename%3Ddcm2niix_lnx.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 888918 (868K) [application/octet-stream]\n",
            "Saving to: ‘dcm2niix_lnx.zip’\n",
            "\n",
            "dcm2niix_lnx.zip    100%[===================>] 868.08K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-06-25 17:39:01 (20.4 MB/s) - ‘dcm2niix_lnx.zip’ saved [888918/888918]\n",
            "\n",
            "Archive:  dcm2niix_lnx.zip\n",
            "  inflating: dcm2niix                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install idc-index\n",
        "# !python3.11 -m pip install idc-index\n",
        "# !python3 -m pip install idc-index\n",
        "\n",
        "# !python3.11 -m pip install idc-index"
      ],
      "metadata": {
        "id": "1Mt9u0zyBBLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from idc_index import index"
      ],
      "metadata": {
        "id": "UaiAP2amZr0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m pip install idc-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7kD6yijcMyV",
        "outputId": "4073b418-d28b-4af9-89d5-27d2a0069830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idc-index\n",
            "  Downloading idc_index-0.5.9-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from idc-index) (8.1.7)\n",
            "Requirement already satisfied: duckdb>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from idc-index) (0.10.3)\n",
            "Collecting idc-index-data==18.0.1 (from idc-index)\n",
            "  Downloading idc_index_data-18.0.1-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from idc-index) (24.1)\n",
            "Requirement already satisfied: pandas<2.2 in /usr/local/lib/python3.10/dist-packages (from idc-index) (2.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from idc-index) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from idc-index) (14.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from idc-index) (2.31.0)\n",
            "Collecting s5cmd (from idc-index)\n",
            "  Downloading s5cmd-0.2.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from idc-index) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2->idc-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2->idc-index) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2->idc-index) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2->idc-index) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->idc-index) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->idc-index) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->idc-index) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->idc-index) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2->idc-index) (1.16.0)\n",
            "Installing collected packages: s5cmd, idc-index-data, idc-index\n",
            "Successfully installed idc-index-0.5.9 idc-index-data-18.0.1 s5cmd-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from idc_index import index"
      ],
      "metadata": {
        "id": "T3COC508cPgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hhaentze/MRSegmentator.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d91a0bd-50cf-4c50-d9c0-e29d14f0ed8b",
        "id": "b0mHkyDuBBK_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MRSegmentator'...\n",
            "remote: Enumerating objects: 328, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 328 (delta 42), reused 42 (delta 29), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (328/328), 1.04 MiB | 17.81 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/MRSegmentator/')\n",
        "sys.path.append('/content/MRSegmentator/src/')"
      ],
      "metadata": {
        "id": "NaVpfrg0BBLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 -m pip install -r MRSegmentator/requirements.txt\n",
        "\n",
        "!python3.11 -m pip install -r MRSegmentator/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057344c3-1c28-4dcc-d55a-17266074bf5d",
        "id": "hlBYu1UnBBLA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnunetv2==2.2.1 (from -r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nnunetv2-2.2.1.tar.gz (178 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/178.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.6/178.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting argparse==1.4.0 (from -r MRSegmentator/requirements.txt (line 2))\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting torch>=2.0.0 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting acvl-utils>=0.2 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading acvl_utils-0.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures>=0.2 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dicom2nifti (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading dicom2nifti-2.4.11-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting scipy (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting batchgenerators>=0.25 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading batchgenerators-0.25.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-image>=0.19.3 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading SimpleITK-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting pandas (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting graphviz (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tifffile (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading tifffile-2024.6.18-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting requests (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting nibabel (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nibabel-5.2.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting matplotlib (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting seaborn (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting imagecodecs (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading imagecodecs-2024.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting yacs (from nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting connected-components-3d (from acvl-utils>=0.2->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading connected_components_3d-3.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Collecting pillow>=7.1.2 (from batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting future (from batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting unittest2 (from batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting threadpoolctl (from batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting networkx>=2.8 (from scikit-image>=0.19.3->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting imageio>=2.33 (from scikit-image>=0.19.3->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting packaging>=21 (from scikit-image>=0.19.3->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image>=0.19.3->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting filelock (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jinja2 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting python-gdcm (from dicom2nifti->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading fonttools-4.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting PyYAML (from yacs->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1)) (1.16.0)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=2.0.0->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.2.1->-r MRSegmentator/requirements.txt (line 1))\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SimpleITK-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tifffile-2024.6.18-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dicom2nifti-2.4.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
            "Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading connected_components_3d-3.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_gdcm-3.0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.2.1-py3-none-any.whl size=237456 sha256=c236b4d9c1b3e1bada1f518eb3d13b21b4902fcc978cc986f8b2019d448a9afd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/86/74/6458fff33248addd98aed21327d80d454cf1c5ff45f1e8a5e5\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22438 sha256=ff1bd777855bda6607049abf5ccdc7ea570b30fb341f0bf02244e956bf9598bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/a2/58/2859b7766f954a14fc5455753075bba345cf6488887f387a8e\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89006 sha256=162ee6b41df980a0fbfc7b3e84e55ead3d45d08f4f93d519c74f387ccbd04993\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/12/11/bdf4821eb4d5eda436725cd38da1842dbf4dc7056b4b0c83e9\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30049 sha256=033d9875001fbf540f40ed72eee64b021c3ef9a5c17a63369938cc0bff03ae8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, pytz, mpmath, linecache2, argparse, urllib3, tzdata, typing-extensions, traceback2, tqdm, threadpoolctl, sympy, PyYAML, python-gdcm, python-dateutil, pyparsing, pydicom, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, graphviz, future, fsspec, fonttools, filelock, cycler, charset-normalizer, certifi, yacs, unittest2, triton, tifffile, scipy, requests, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nibabel, lazy-loader, jinja2, imageio, imagecodecs, contourpy, connected-components-3d, scikit-learn, scikit-image, nvidia-cusolver-cu12, matplotlib, dicom2nifti, torch, seaborn, batchgenerators, dynamic-network-architectures, acvl-utils, nnunetv2\n",
            "Successfully installed MarkupSafe-2.1.5 PyYAML-6.0.1 SimpleITK-2.3.1 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 certifi-2024.6.2 charset-normalizer-3.3.2 connected-components-3d-3.17.0 contourpy-1.2.1 cycler-0.12.1 dicom2nifti-2.4.11 dynamic-network-architectures-0.3.1 filelock-3.15.4 fonttools-4.53.0 fsspec-2024.6.0 future-1.0.0 graphviz-0.20.3 idna-3.7 imagecodecs-2024.6.1 imageio-2.34.2 jinja2-3.1.4 joblib-1.4.2 kiwisolver-1.4.5 lazy-loader-0.4 linecache2-1.0.0 matplotlib-3.9.0 mpmath-1.3.0 networkx-3.3 nibabel-5.2.1 nnunetv2-2.2.1 numpy-2.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 packaging-24.1 pandas-2.2.2 pillow-10.3.0 pydicom-2.4.4 pyparsing-3.1.2 python-dateutil-2.9.0.post0 python-gdcm-3.0.24.1 pytz-2024.1 requests-2.32.3 scikit-image-0.24.0 scikit-learn-1.5.0 scipy-1.14.0 seaborn-0.13.2 sympy-1.12.1 threadpoolctl-3.5.0 tifffile-2024.6.18 torch-2.3.1 tqdm-4.66.4 traceback2-1.4.0 triton-2.3.1 typing-extensions-4.12.2 tzdata-2024.1 unittest2-1.1.0 urllib3-2.2.2 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.11 -m pip install --upgrade mrsegmentator==1.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91ziv1L4HuSC",
        "outputId": "f1f6a062-ef5b-4e70-fa7e-196e17d429b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrsegmentator==1.1\n",
            "  Downloading mrsegmentator-1.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: nnunetv2==2.2.1 in /usr/local/lib/python3.11/dist-packages (from mrsegmentator==1.1) (2.2.1)\n",
            "Collecting argparse (from mrsegmentator==1.1)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting monai==1.3.0 (from mrsegmentator==1.1)\n",
            "  Downloading monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from monai==1.3.0->mrsegmentator==1.1) (2.0.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai==1.3.0->mrsegmentator==1.1) (2.3.1)\n",
            "Requirement already satisfied: acvl-utils>=0.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.2)\n",
            "Requirement already satisfied: dynamic-network-architectures>=0.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (4.66.4)\n",
            "Requirement already satisfied: dicom2nifti in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2.4.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (1.14.0)\n",
            "Requirement already satisfied: batchgenerators>=0.25 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.25)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (1.5.0)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.24.0)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.20.3)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2024.6.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (5.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (3.9.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.13.2)\n",
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (2024.6.1)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.2.1->mrsegmentator==1.1) (0.1.8)\n",
            "Requirement already satisfied: connected-components-3d in /usr/local/lib/python3.11/dist-packages (from acvl-utils>=0.2->nnunetv2==2.2.1->mrsegmentator==1.1) (3.17.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (10.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (1.0.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (3.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1->mrsegmentator==1.1) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1->mrsegmentator==1.1) (2.34.2)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1->mrsegmentator==1.1) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2.1->mrsegmentator==1.1) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (2024.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (12.5.40)\n",
            "Requirement already satisfied: pydicom>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from dicom2nifti->nnunetv2==2.2.1->mrsegmentator==1.1) (2.4.4)\n",
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.11/dist-packages (from dicom2nifti->nnunetv2==2.2.1->mrsegmentator==1.1) (3.0.24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.2.1->mrsegmentator==1.1) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.2.1->mrsegmentator==1.1) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.2.1->mrsegmentator==1.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.2.1->mrsegmentator==1.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.2.1->mrsegmentator==1.1) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.2.1->mrsegmentator==1.1) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2==2.2.1->mrsegmentator==1.1) (1.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2==2.2.1->mrsegmentator==1.1) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.2.1->mrsegmentator==1.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9->monai==1.3.0->mrsegmentator==1.1) (1.3.0)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.11/dist-packages (from unittest2->batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (1.4.0)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.11/dist-packages (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.2.1->mrsegmentator==1.1) (1.0.0)\n",
            "Downloading mrsegmentator-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse, monai, mrsegmentator\n",
            "Successfully installed argparse-1.4.0 monai-1.3.0 mrsegmentator-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run inference on IDC data"
      ],
      "metadata": {
        "id": "aiHIIbZqflWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Could use this to find appropriate patients\n",
        "\n",
        "# MRSegmentator was trained on (UK Biobank) Dixon technique: in-phase (IN), opposed-phase (OPP), fat-only (F), and water-only (W) and\n",
        "# in house:\n",
        "# abdominal MRI scans from 177 patients with kidney tumors and cysts, yielding 221 scans.\n",
        "# Tumor size is below 7 cm for 213 scans and goes up to 13 cm in the remaining 8 scans.\n",
        "# This dataset has an approximately equal distribution of T1, T2, and T1-weighted-fat-saturated (T1fs) sequences.\n",
        "\n",
        "# SELECT\n",
        "#   collection_id,\n",
        "#   PatientID,\n",
        "#   StudyInstanceUID,\n",
        "#   SeriesInstanceUID,\n",
        "#   CONCAT(\"https://viewer.imaging.datacommons.cancer.gov/viewer/\",\n",
        "#         StudyInstanceUID,\n",
        "#             \"?seriesInstanceUID=\",\n",
        "#           SeriesInstanceUID) as viewer_url\n",
        "# FROM\n",
        "#   `bigquery-public-data.idc_current.dicom_all`\n",
        "# WHERE\n",
        "#   Modality = \"MR\" AND\n",
        "#   SeriesDescription LIKE '%dixon%'\n",
        "\n",
        "# This study https://viewer.imaging.datacommons.cancer.gov/viewer/1.3.6.1.4.1.14519.5.2.1.8421.4018.304030957341830836628192929917\n",
        "# comes from TCGA_READ - rectal carcinoma\n",
        "# has series for in, opp, f and w\n",
        "# in = 1.3.6.1.4.1.14519.5.2.1.8421.4018.245899486818595639456807603739\n",
        "# out = 1.3.6.1.4.1.14519.5.2.1.8421.4018.198461476658037865560948236665\n",
        "# f = 1.3.6.1.4.1.14519.5.2.1.8421.4018.665800588212969580449101793069\n",
        "# w = 1.3.6.1.4.1.14519.5.2.1.8421.4018.303561813582038351658059976611"
      ],
      "metadata": {
        "id": "4rRI7xKLeP1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference in loop\n",
        "\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "series_type_list = ['in', 'out', 'fat', 'water']\n",
        "series_uid_list = ['1.3.6.1.4.1.14519.5.2.1.8421.4018.245899486818595639456807603739',\n",
        "                   '1.3.6.1.4.1.14519.5.2.1.8421.4018.198461476658037865560948236665',\n",
        "                   '1.3.6.1.4.1.14519.5.2.1.8421.4018.665800588212969580449101793069',\n",
        "                   '1.3.6.1.4.1.14519.5.2.1.8421.4018.303561813582038351658059976611']"
      ],
      "metadata": {
        "id": "Ow6wDbDyc7WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "idc_client = index.IDCClient()"
      ],
      "metadata": {
        "id": "pyNohryydQ6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/raw'):\n",
        "  shutil.rmtree(\"/content/raw\")\n",
        "if os.path.exists('/content/nii'):\n",
        "  shutil.rmtree(\"/content/nii\")"
      ],
      "metadata": {
        "id": "AqOYbpSphSrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(0,len(series_uid_list)):\n",
        "\n",
        "  series_uid = series_uid_list[n]\n",
        "  series_type = series_type_list[n]\n",
        "\n",
        "  # Download MR files\n",
        "  download_path = \"/content/raw\"\n",
        "  if not os.path.isdir(download_path):\n",
        "    os.mkdir(download_path)\n",
        "\n",
        "  # Download using s5cmd\n",
        "  idc_client.download_dicom_series(series_uid, download_path)\n",
        "\n",
        "  # Convert to nifti\n",
        "  nifti_directory = \"/content/nii\"\n",
        "  if not os.path.isdir(nifti_directory):\n",
        "    os.mkdir(nifti_directory)\n",
        "\n",
        "  cmd = 'dcm2niix -z y -m y -o %s  %s ' % (nifti_directory, download_path)\n",
        "  print(cmd)\n",
        "  ret = os.system(cmd)\n",
        "  print(ret)\n",
        "\n",
        "  # Rename file\n",
        "  nii_file_orig = [os.path.join(nifti_directory,f) for f in os.listdir(nifti_directory) if f.endswith('.nii.gz')][0]\n",
        "  nii_file = \"/content/mri_image_\" + str(series_type) + \".nii.gz\"\n",
        "  os.rename(nii_file_orig, nii_file)\n",
        "\n",
        "  # output file\n",
        "  output_directory = \"/content/output_\" + str(series_type)\n",
        "  if not os.path.isdir(output_directory):\n",
        "    os.mkdir(output_directory)\n",
        "  nii_seg_file = os.path.join(output_directory, \"mri_image_\" + str(series_type) + \"_seg.nii.gz\")\n",
        "\n",
        "  # Run inference\n",
        "  !mrsegmentator --input $nii_file --outdir $output_directory --split_level 1 --nproc 2 --nproc_export 2 --verbose # 1 minute to run\n",
        "\n",
        "  # delete raw DICOM files\n",
        "  shutil.rmtree(download_path)\n",
        "\n",
        "  # download nifti files - MR and SEG\n",
        "  # files.download(nii_file)\n",
        "  # files.download(nii_seg_file)\n",
        "\n",
        "  # delete nii files\n",
        "  shutil.rmtree('/content/nii')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XSzNRUkxdNIh",
        "outputId": "34dd3305-8615-4a53-b3bc-033e962dc681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|█████████▉| 10.4M/10.4M [00:01<00:00, 10.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o /content/nii  /content/raw \n",
            "0\n",
            "Processing image 1 out of 1 images.\n",
            "Read /content/mri_image_in.nii.gz\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7e0a3d76b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 12.09it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.85it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.87it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.82it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.84it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7e0a3d76b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 15.66it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.78it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.83it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.74it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.66it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "Write /content/output_in/mri_image_in_seg.nii.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ff9d3c1a-7bf2-43ae-9903-6f788af85750\", \"mri_image_in.nii.gz\", 5019516)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_090b203b-b44d-4b66-b05c-573b61dea980\", \"mri_image_in_seg.nii.gz\", 74296)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|█████████▉| 10.4M/10.4M [00:01<00:00, 6.90MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o /content/nii  /content/raw \n",
            "0\n",
            "Processing image 1 out of 1 images.\n",
            "Read /content/mri_image_out.nii.gz\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7af40581b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 11.98it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.69it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.63it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.60it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.58it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7af40581b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 15.65it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.64it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.51it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.56it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.45it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "Write /content/output_out/mri_image_out_seg.nii.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b4eab05d-3c4f-4e0a-83a4-7797d398c252\", \"mri_image_out.nii.gz\", 5111630)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e753efb0-3e60-40c6-a1fc-2d48a31e385e\", \"mri_image_out_seg.nii.gz\", 78554)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|█████████▉| 10.4M/10.4M [00:01<00:00, 6.91MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o /content/nii  /content/raw \n",
            "0\n",
            "Processing image 1 out of 1 images.\n",
            "Read /content/mri_image_fat.nii.gz\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7963f617b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 11.90it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.47it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.41it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.50it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.35it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7963f617b6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 15.84it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.54it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.50it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.50it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.43it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "Write /content/output_fat/mri_image_fat_seg.nii.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_14405992-ee4b-4971-af16-2efca6dcbcdb\", \"mri_image_fat.nii.gz\", 4855949)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a00a7cf-82b5-4d77-bd7a-a6b54d9ba991\", \"mri_image_fat_seg.nii.gz\", 76649)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|█████████▉| 10.4M/10.4M [00:01<00:00, 6.89MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o /content/nii  /content/raw \n",
            "0\n",
            "Processing image 1 out of 1 images.\n",
            "Read /content/mri_image_water.nii.gz\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7a399ce0f6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 11.68it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.49it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.53it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.56it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.48it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7a399ce0f6a0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 15.58it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.56it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.45it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.41it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 17.50it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "Write /content/output_water/mri_image_water_seg.nii.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_013ea22f-8bab-4d47-b12b-ca4d77b93345\", \"mri_image_water.nii.gz\", 4258626)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fffcc13a-8066-4460-90b3-315f7ee696e8\", \"mri_image_water_seg.nii.gz\", 81128)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old"
      ],
      "metadata": {
        "id": "A_L7JkYbddXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "idc_client = index.IDCClient()\n",
        "\n",
        "# Sample series\n",
        "series_uid = \"1.3.6.1.4.1.14519.5.2.1.8421.4018.245899486818595639456807603739\"  # in phase\n",
        "\n",
        "# Download MR files\n",
        "download_path = \"/content/raw\"\n",
        "if not os.path.isdir(download_path):\n",
        "  os.mkdir(download_path)\n",
        "\n",
        "# Download using s5cmd\n",
        "idc_client.download_dicom_series(series_uid, download_path)"
      ],
      "metadata": {
        "id": "JM_JVgZoX6FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ce2fb8-a496-4984-ee55-332bfc00028b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data: 100%|█████████▉| 10.4M/10.4M [00:05<00:00, 2.08MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to nifti\n",
        "nifti_directory = \"/content/nii\"\n",
        "if not os.path.isdir(nifti_directory):\n",
        "  os.mkdir(nifti_directory)\n",
        "\n",
        "cmd = 'dcm2niix -z y -m y -o %s  %s ' % (nifti_directory, download_path)\n",
        "print(cmd)\n",
        "ret = os.system(cmd)\n",
        "print(ret)\n",
        "\n",
        "# Rename file\n",
        "nii_file_orig = [os.path.join(nifti_directory,f) for f in os.listdir(nifti_directory) if f.endswith('.nii.gz')][0]\n",
        "nii_file = \"/content/mri_image.nii.gz\"\n",
        "os.rename(nii_file_orig, nii_file)"
      ],
      "metadata": {
        "id": "oo1zouf_X6FZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9135981d-951e-4709-b663-4a27663d849b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcm2niix -z y -m y -o /content/nii  /content/raw \n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mrsegmentator --input /content/mri_image.nii.gz --outdir /content/output --split_level 1 --nproc 2 --nproc_export 2 --verbose # 1 minute to run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyD_kLdNXy8h",
        "outputId": "4e543115-5e47-402c-8e8f-47f381f2dfda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image 1 out of 1 images.\n",
            "Read /content/mri_image.nii.gz\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x79f6c8ea2de0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:01<00:00,  6.36it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.52it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.58it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.51it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.46it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "preprocessing\n",
            "old shape: (34, 250, 319), new_shape: [ 79 234 299], old_spacing: [3.5, 1.40625, 1.40625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x79f6c8ea2de0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
            "predicting\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 14.69it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.33it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.23it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.23it/s]\n",
            "Input shape: torch.Size([1, 79, 234, 299])\n",
            "step_size: 0.5\n",
            "mirror_axes: None\n",
            "n_steps 9, image size is torch.Size([96, 234, 299]), tile_size [96, 128, 160], tile_step_size 0.5\n",
            "steps:\n",
            "[[0], [0, 53, 106], [0, 70, 139]]\n",
            "preallocating arrays\n",
            "running prediction\n",
            "100% 9/9 [00:00<00:00, 16.19it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "resampling to original shape\n",
            "Write /content/output/mri_image_seg.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emYJVMZFl_Cq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}